{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUE/YDL8WGS93zHqprz+5A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akanshapawar21/akanshapawar/blob/main/Mod_02_Lab_02_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKz3Z25hT9Xc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_breast_cancer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breast_data = load_breast_cancer().data\n",
        "print(\"Features:\", breast_data.shape)  ### 569 rows and 30 columns expected\n",
        "\n",
        "breast_labels = np.reshape(load_breast_cancer().target, (569,1))\n",
        "print(\"Target:\", breast_labels.shape) ### 569 rows and 1 target column expected"
      ],
      "metadata": {
        "id": "I-GiGmAZUNOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a Pandas dataframe for the dataset with the last column as the target variable\n",
        "\n",
        "final_breast_data = np.concatenate([breast_data, breast_labels],axis=1)\n",
        "breast_dataset = pd.DataFrame(final_breast_data)\n",
        "\n",
        "features = load_breast_cancer().feature_names\n",
        "features_labels = np.append(features,'label')\n",
        "breast_dataset.columns = features_labels\n",
        "breast_dataset.head()"
      ],
      "metadata": {
        "id": "BLt67d1jUNK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividing the values into the features and labels for convenience later on\n",
        "\n",
        "X = breast_dataset.iloc[:,:30].values\n",
        "y = breast_dataset.iloc[:,30].values\n",
        "\n",
        "print(np.shape(X), np.shape(y))"
      ],
      "metadata": {
        "id": "duLNBkySUNIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X_std = StandardScaler().fit_transform(X)\n",
        "\n",
        "print(np.std(X_std))"
      ],
      "metadata": {
        "id": "rMFj2ZFKUNFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_std_df = pd.DataFrame(X_std)\n",
        "X_std_df.columns = features\n",
        "X_std_df.head()"
      ],
      "metadata": {
        "id": "h9eGL-OUUNDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Computing the covariance matrix\n",
        "Recall that covariance is always measured between 2 dimensions. If we have a data set with more than 2 dimensions, there is more than one covariance measurement that can be calculated. For example, from a 3 dimensional data set (dimensions x,y,z) you could calculate cov(x,y), cov(y,z) and cov(x,z). In fact, for an n-dimensional data set, you can calculate N combinatorial 2 different covariances.\n",
        "\n",
        "Here we have 30 different features, so we will have to compute 435 different covariances."
      ],
      "metadata": {
        "id": "qHtTOGirUhfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_vec = np.mean(X_std, axis=0) ## Computing feature wise means\n",
        "\n",
        "# Covariance matrix = i/(N-1) * X^T * X\n",
        "# where X is the normalized feature matrix and N is the number of data points (rows)\n",
        "\n",
        "cov_mat = 1/ (X_std.shape[0]-1) * (X_std - mean_vec).T.dot(X_std - mean_vec)\n",
        "\n",
        "print(\"Covariance matrix first 5 rows and columns:\")\n",
        "print(cov_mat[0:5, 0:5])"
      ],
      "metadata": {
        "id": "HXR88c_XUNAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cov_mat.shape"
      ],
      "metadata": {
        "id": "4w30sMwfUM-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cov_mat_numpy = np.cov(X_std.T)\n",
        "\n",
        "print(\"Covariance matrix first 5 rows and columns:\")\n",
        "print(cov_mat_numpy[0:5, 0:5])"
      ],
      "metadata": {
        "id": "aY8UZYV5UM7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eig_vals, eig_vecs = np.linalg.eig(cov_mat)"
      ],
      "metadata": {
        "id": "V1eaCVndUq6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eig_vals.shape, eig_vecs.shape"
      ],
      "metadata": {
        "id": "4_ofFiBrUq3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Computing the Principal Components"
      ],
      "metadata": {
        "id": "cZRhq8EPVrg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
        "eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "tot = sum(eig_vals)\n",
        "var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
        "print(\"Explained variance:\")\n",
        "print(var_exp)\n",
        "\n",
        "cum_var_exp = np.cumsum(var_exp)\n",
        "print(\"Cumulative explained variance:\")\n",
        "print(cum_var_exp)\n",
        "\n",
        "# Plotting the variance explained by each component and the cumulative variance explained\n",
        "\n",
        "plt.figure(figsize=(6 , 4))\n",
        "plt.bar(range(30), var_exp, alpha=0.5, align='center', label='individual explained variance')\n",
        "plt.step(range(30), cum_var_exp, where='mid', label='cumulative explained variance')\n",
        "plt.ylabel('Explained variance ratio')\n",
        "plt.xlabel('Principal components')\n",
        "plt.legend(loc='best')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W9YRsrwMUq1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_w = np.hstack((eig_pairs[0][1].reshape(30,1),\n",
        "                      eig_pairs[1][1].reshape(30,1),\n",
        "                      eig_pairs[2][1].reshape(30,1)))\n",
        "\n",
        "Y = X_std.dot(matrix_w)\n",
        "\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "RBavBo3TUqyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "sklearn_pca = PCA(n_components=3)\n",
        "Y_sklearn = sklearn_pca.fit_transform(X_std)\n",
        "\n",
        "print(Y_sklearn)"
      ],
      "metadata": {
        "id": "Y6TP-7oKUqv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.DataFrame(columns=[\"PC1\", \"PC2\", \"PC3\", \"Label\"])\n",
        "\n",
        "for i in range(len(Y)):\n",
        "\n",
        "    dicti = dict()\n",
        "\n",
        "    dicti[\"PC1\"] = Y[i, 0]\n",
        "    dicti[\"PC2\"] = Y[i, 1]\n",
        "    dicti[\"PC3\"] = Y[i, 2]\n",
        "    if (int(breast_labels[i][0]) == 0):\n",
        "      dicti[\"Label\"] = \"Benign\"\n",
        "    else:\n",
        "      dicti[\"Label\"] = \"Malignant\"\n",
        "\n",
        "    final_df = pd.concat([final_df, pd.DataFrame([dicti])], ignore_index=True)\n",
        "\n",
        "\n",
        "final_df.head()"
      ],
      "metadata": {
        "id": "CTHjiY3eUqtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "import plotly.express as px"
      ],
      "metadata": {
        "id": "eYR0uOK2Uqq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for_x = final_df.PC1.tolist()\n",
        "for_y = final_df.PC2.tolist()\n",
        "for_label = final_df.Label.tolist()\n",
        "for_hover = final_df.Label.tolist()\n",
        "\n",
        "fig = px.scatter(x=for_x, y=for_y, color=for_label,\n",
        "                 title=\"Principal Component Axis\",\n",
        "                 color_discrete_map={\"Benign\": \"aqua\", \"Malignant\": \"yellow\"})\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis=dict(title = 'PC1', showgrid=True, ticks='inside', zeroline=True, mirror=True, showline=True, linecolor='white'),\n",
        "    yaxis=dict(title = 'PC2', showgrid=True, ticks='inside', zeroline=True, mirror=True, showline=True, linecolor='white'),\n",
        "    plot_bgcolor='#555555',\n",
        "    font=dict(\n",
        "        family=\"Times New Roman\",\n",
        "        size=16,\n",
        "        color=\"Black\"))\n",
        "fig.update_traces(marker=dict(size=8,))\n",
        "\n",
        "fig.show(renderer = \"colab\")"
      ],
      "metadata": {
        "id": "NZGr33CFUqoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question:\n",
        "Referring to the plot above, can you reason why PCA can be a good candidate before training models for Machine learning?\n",
        "\n",
        "Answer:\n",
        "You can see that the first 2 principal components were able to differentiate the benign and malignant tumours in our breast cancer dataset. This motivates the use of the second application of PCA, which was to reduce the number of features in the dataset so that the machine learning algorithm can be trained without overfitting.\n",
        "\n",
        "Let us now try and visualize this in the first 3 Principal Components space."
      ],
      "metadata": {
        "id": "pONFmRsqWUF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter_3d(final_df, x='PC1', y='PC2', z='PC3', color='Label', title=\"Principal Component Axis\")\n",
        "fig.update_traces(marker=dict(size=6,))\n",
        "\n",
        "fig.show(renderer = \"colab\")"
      ],
      "metadata": {
        "id": "vIbXvbCrWYq4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}